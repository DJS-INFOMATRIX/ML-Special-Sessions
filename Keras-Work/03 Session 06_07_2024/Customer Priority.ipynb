{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, concatenate\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy data\n",
    "titles = [\"Help with order\", \"Issue with payment\", \"Login problem\"]\n",
    "bodies = [\"I cannot find my order\", \"Payment method not working\", \"Cannot log in to my account\"]\n",
    "tags = [0, 1, 2]  # categorical tags\n",
    "\n",
    "# Tokenize the text inputs\n",
    "tokenizer = Tokenizer(num_words=100)\n",
    "tokenizer.fit_on_texts(titles + bodies)\n",
    "title_sequences = tokenizer.texts_to_sequences(titles)\n",
    "body_sequences = tokenizer.texts_to_sequences(bodies)\n",
    "\n",
    "# Pad the sequences\n",
    "title_data = pad_sequences(title_sequences, maxlen=5)\n",
    "body_data = pad_sequences(body_sequences, maxlen=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the tags\n",
    "tag_data = to_categorical(tags, num_classes=3)\n",
    "\n",
    "# Dummy outputs\n",
    "priority_scores = np.random.rand(len(titles), 1)\n",
    "departments = np.random.randint(0, 3, len(titles))\n",
    "department_data = to_categorical(departments, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model inputs\n",
    "title_input = Input(shape=(5,), name='title_input')\n",
    "body_input = Input(shape=(20,), name='body_input')\n",
    "tag_input = Input(shape=(3,), name='tag_input')\n",
    "\n",
    "# Embedding and LSTM layers for text inputs\n",
    "embedding_layer = Embedding(input_dim=100, output_dim=10, input_length=5)\n",
    "title_embeddings = embedding_layer(title_input)\n",
    "title_lstm = LSTM(32)(title_embeddings)\n",
    "\n",
    "embedding_layer_body = Embedding(input_dim=100, output_dim=10, input_length=20)\n",
    "body_embeddings = embedding_layer_body(body_input)\n",
    "body_lstm = LSTM(32)(body_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all inputs\n",
    "concat_layer = concatenate([title_lstm, body_lstm, tag_input])\n",
    "\n",
    "# Dense layers for output\n",
    "dense1 = Dense(64, activation='relu')(concat_layer)\n",
    "priority_output = Dense(1, activation='sigmoid', name='priority_output')(dense1)\n",
    "department_output = Dense(3, activation='softmax', name='department_output')(dense1)\n",
    "\n",
    "# Model definition\n",
    "model = Model(inputs=[title_input, body_input, tag_input], outputs=[priority_output, department_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss={'priority_output': 'binary_crossentropy', 'department_output': 'categorical_crossentropy'},\n",
    "              metrics={'priority_output': 'accuracy', 'department_output': 'accuracy'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0s/step - department_output_accuracy: 0.7778 - loss: 1.7273 - priority_output_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - department_output_accuracy: 0.7778 - loss: 1.6980 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 3/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - department_output_accuracy: 0.6111 - loss: 1.6922 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 4/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - department_output_accuracy: 0.6111 - loss: 1.6681 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 5/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - department_output_accuracy: 0.7778 - loss: 1.6279 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 6/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - department_output_accuracy: 0.7778 - loss: 1.5997 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 7/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - department_output_accuracy: 0.6111 - loss: 1.5899 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 8/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - department_output_accuracy: 0.6111 - loss: 1.5744 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 9/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - department_output_accuracy: 0.6111 - loss: 1.5303 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 10/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - department_output_accuracy: 0.7778 - loss: 1.4771 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 11/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - department_output_accuracy: 0.6111 - loss: 1.4662 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 12/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - department_output_accuracy: 1.0000 - loss: 1.4048 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 13/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - department_output_accuracy: 1.0000 - loss: 1.3919 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 14/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - department_output_accuracy: 1.0000 - loss: 1.3475 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 15/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - department_output_accuracy: 1.0000 - loss: 1.3085 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 16/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - department_output_accuracy: 1.0000 - loss: 1.2540 - priority_output_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - department_output_accuracy: 0.7778 - loss: 1.1414 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 18/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - department_output_accuracy: 0.7778 - loss: 1.0731 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 19/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - department_output_accuracy: 0.6111 - loss: 1.1055 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 20/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - department_output_accuracy: 0.7778 - loss: 0.9804 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 21/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - department_output_accuracy: 0.7778 - loss: 0.9461 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 22/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - department_output_accuracy: 1.0000 - loss: 1.0509 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 23/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - department_output_accuracy: 1.0000 - loss: 1.0138 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 24/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - department_output_accuracy: 1.0000 - loss: 0.9352 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 25/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - department_output_accuracy: 1.0000 - loss: 0.9873 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 26/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - department_output_accuracy: 1.0000 - loss: 0.9690 - priority_output_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - department_output_accuracy: 1.0000 - loss: 0.9761 - priority_output_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - department_output_accuracy: 1.0000 - loss: 0.8787 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 29/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - department_output_accuracy: 1.0000 - loss: 0.9335 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 30/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - department_output_accuracy: 1.0000 - loss: 0.9393 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 31/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - department_output_accuracy: 1.0000 - loss: 0.9277 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 32/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - department_output_accuracy: 1.0000 - loss: 0.8215 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 33/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - department_output_accuracy: 1.0000 - loss: 0.8918 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 34/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - department_output_accuracy: 1.0000 - loss: 0.7944 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 35/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - department_output_accuracy: 1.0000 - loss: 0.8765 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 36/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - department_output_accuracy: 1.0000 - loss: 0.8409 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 37/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - department_output_accuracy: 1.0000 - loss: 0.8243 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 38/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - department_output_accuracy: 1.0000 - loss: 0.8283 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 39/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - department_output_accuracy: 1.0000 - loss: 0.8144 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 40/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - department_output_accuracy: 1.0000 - loss: 0.8020 - priority_output_accuracy: 0.0000e+00  \n",
      "Epoch 41/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - department_output_accuracy: 1.0000 - loss: 0.7730 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 42/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - department_output_accuracy: 1.0000 - loss: 0.7808 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 43/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - department_output_accuracy: 1.0000 - loss: 0.7540 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 44/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - department_output_accuracy: 1.0000 - loss: 0.7417 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 45/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - department_output_accuracy: 1.0000 - loss: 0.7435 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 46/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - department_output_accuracy: 1.0000 - loss: 0.7288 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 47/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - department_output_accuracy: 1.0000 - loss: 0.6994 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 48/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - department_output_accuracy: 1.0000 - loss: 0.6365 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 49/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - department_output_accuracy: 1.0000 - loss: 0.6260 - priority_output_accuracy: 0.0000e+00 \n",
      "Epoch 50/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - department_output_accuracy: 1.0000 - loss: 0.6615 - priority_output_accuracy: 0.0000e+00 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f0ef7273e0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model on dummy data\n",
    "model.fit([title_data, body_data, tag_data], \n",
    "          [priority_scores, department_data], \n",
    "          epochs=50, \n",
    "          batch_size=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
