{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import keras\n",
    "from keras.utils import FeatureSpace\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://archive.ics.uci.edu/static/public/222/bank+marketing.zip\n",
      " 909312/Unknown \u001b[1m2s\u001b[0m 2us/step"
     ]
    }
   ],
   "source": [
    "data_url = \"https://archive.ics.uci.edu/static/public/222/bank+marketing.zip\"\n",
    "data_zipped_path = keras.utils.get_file(\"bank_marketing.zip\", data_url, extract=True)\n",
    "keras_datasets_path = Path(data_zipped_path).parents[0]\n",
    "with ZipFile(f\"{keras_datasets_path}/bank-additional.zip\", \"r\") as zip:\n",
    "    # Extract files\n",
    "    zip.extractall(path=keras_datasets_path)\n",
    "\n",
    "dataframe = pd.read_csv(\n",
    "    f\"{keras_datasets_path}/bank-additional/bank-additional.csv\", sep=\";\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping `duration` to avoid target leak\n",
    "dataframe.drop(\"duration\", axis=1, inplace=True)\n",
    "# Creating the new feature `previously_contacted`\n",
    "dataframe[\"previously_contacted\"] = dataframe[\"pdays\"].map(\n",
    "    lambda x: 0 if x == 999 else 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape: (4119, 21)\n",
      "   age          job  marital          education default  housing     loan  \\\n",
      "0   30  blue-collar  married           basic.9y      no      yes       no   \n",
      "1   39     services   single        high.school      no       no       no   \n",
      "2   25     services  married        high.school      no      yes       no   \n",
      "3   38     services  married           basic.9y      no  unknown  unknown   \n",
      "4   47       admin.  married  university.degree      no      yes       no   \n",
      "\n",
      "     contact month day_of_week  ...  pdays  previous     poutcome  \\\n",
      "0   cellular   may         fri  ...    999         0  nonexistent   \n",
      "1  telephone   may         fri  ...    999         0  nonexistent   \n",
      "2  telephone   jun         wed  ...    999         0  nonexistent   \n",
      "3  telephone   jun         fri  ...    999         0  nonexistent   \n",
      "4   cellular   nov         mon  ...    999         0  nonexistent   \n",
      "\n",
      "  emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \\\n",
      "0         -1.8          92.893          -46.2      1.313       5099.1  no   \n",
      "1          1.1          93.994          -36.4      4.855       5191.0  no   \n",
      "2          1.4          94.465          -41.8      4.962       5228.1  no   \n",
      "3          1.4          94.465          -41.8      4.959       5228.1  no   \n",
      "4         -0.1          93.200          -42.0      4.191       5195.8  no   \n",
      "\n",
      "  previously_contacted  \n",
      "0                    0  \n",
      "1                    0  \n",
      "2                    0  \n",
      "3                    0  \n",
      "4                    0  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataframe shape: {dataframe.shape}\")\n",
    "print(dataframe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 3295 samples for training and 824 for validation\n"
     ]
    }
   ],
   "source": [
    "valid_dataframe = dataframe.sample(frac=0.2, random_state=0)\n",
    "train_dataframe = dataframe.drop(valid_dataframe.index)\n",
    "\n",
    "print(\n",
    "    f\"Using {len(train_dataframe)} samples for training and \"\n",
    "    f\"{len(valid_dataframe)} for validation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_lookup = keras.layers.StringLookup(\n",
    "    # the order here is important since the first index will be encoded as 0\n",
    "    vocabulary=[\"no\", \"yes\"],\n",
    "    num_oov_indices=0,\n",
    ")\n",
    "\n",
    "\n",
    "def encode_label(x, y):\n",
    "    encoded_y = label_lookup(y)\n",
    "    return x, encoded_y\n",
    "\n",
    "\n",
    "def dataframe_to_dataset(dataframe):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop(\"y\")\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    ds = ds.map(encode_label, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    return ds\n",
    "\n",
    "\n",
    "train_ds = dataframe_to_dataset(train_dataframe)\n",
    "valid_ds = dataframe_to_dataset(valid_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: {'age': <tf.Tensor: shape=(), dtype=int64, numpy=31>, 'job': <tf.Tensor: shape=(), dtype=string, numpy=b'admin.'>, 'marital': <tf.Tensor: shape=(), dtype=string, numpy=b'married'>, 'education': <tf.Tensor: shape=(), dtype=string, numpy=b'high.school'>, 'default': <tf.Tensor: shape=(), dtype=string, numpy=b'no'>, 'housing': <tf.Tensor: shape=(), dtype=string, numpy=b'no'>, 'loan': <tf.Tensor: shape=(), dtype=string, numpy=b'no'>, 'contact': <tf.Tensor: shape=(), dtype=string, numpy=b'telephone'>, 'month': <tf.Tensor: shape=(), dtype=string, numpy=b'jun'>, 'day_of_week': <tf.Tensor: shape=(), dtype=string, numpy=b'thu'>, 'campaign': <tf.Tensor: shape=(), dtype=int64, numpy=4>, 'pdays': <tf.Tensor: shape=(), dtype=int64, numpy=999>, 'previous': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'poutcome': <tf.Tensor: shape=(), dtype=string, numpy=b'nonexistent'>, 'emp.var.rate': <tf.Tensor: shape=(), dtype=float64, numpy=1.4>, 'cons.price.idx': <tf.Tensor: shape=(), dtype=float64, numpy=94.465>, 'cons.conf.idx': <tf.Tensor: shape=(), dtype=float64, numpy=-41.8>, 'euribor3m': <tf.Tensor: shape=(), dtype=float64, numpy=4.961>, 'nr.employed': <tf.Tensor: shape=(), dtype=float64, numpy=5228.1>, 'previously_contacted': <tf.Tensor: shape=(), dtype=int64, numpy=0>}\n",
      "Target: 1\n"
     ]
    }
   ],
   "source": [
    "for x, y in dataframe_to_dataset(train_dataframe).take(1):\n",
    "    print(f\"Input: {x}\")\n",
    "    print(f\"Target: {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_with_no_labels = train_ds.map(lambda x, _: x)\n",
    "\n",
    "\n",
    "def example_feature_space(dataset, feature_space, feature_names):\n",
    "    feature_space.adapt(dataset)\n",
    "    for x in dataset.take(1):\n",
    "        inputs = {feature_name: x[feature_name] for feature_name in feature_names}\n",
    "        preprocessed_x = feature_space(inputs)\n",
    "        print(f\"Input: {[{k:v.numpy()} for k, v in inputs.items()]}\")\n",
    "        print(\n",
    "            f\"Preprocessed output: {[{k:v.numpy()} for k, v in preprocessed_x.items()]}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [{'campaign': 3}]\n",
      "Preprocessed output: [{'campaign': array([0., 1., 0., 0.], dtype=float32)}]\n"
     ]
    }
   ],
   "source": [
    "feature_space = FeatureSpace(\n",
    "    features={\n",
    "        \"campaign\": FeatureSpace.integer_hashed(num_bins=4, output_mode=\"one_hot\")\n",
    "    },\n",
    "    output_mode=\"dict\",\n",
    ")\n",
    "example_feature_space(train_ds_with_no_labels, feature_space, [\"campaign\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [{'education': b'unknown'}]\n",
      "Preprocessed output: [{'education': array([0., 1., 0.], dtype=float32)}]\n"
     ]
    }
   ],
   "source": [
    "feature_space = FeatureSpace(\n",
    "    features={\n",
    "        \"education\": FeatureSpace.string_hashed(num_bins=3, output_mode=\"one_hot\")\n",
    "    },\n",
    "    output_mode=\"dict\",\n",
    ")\n",
    "example_feature_space(train_ds_with_no_labels, feature_space, [\"education\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [{'age': 23}]\n",
      "Preprocessed output: [{'age': array([1., 0., 0.], dtype=float32)}]\n"
     ]
    }
   ],
   "source": [
    "feature_space = FeatureSpace(\n",
    "    features={\"age\": FeatureSpace.float_discretized(num_bins=3, output_mode=\"one_hot\")},\n",
    "    output_mode=\"dict\",\n",
    ")\n",
    "example_feature_space(train_ds_with_no_labels, feature_space, [\"age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [{'default': b'no'}]\n",
      "Preprocessed output: [{'default': array([0., 1., 0., 0.], dtype=float32)}]\n"
     ]
    }
   ],
   "source": [
    "feature_space = FeatureSpace(\n",
    "    features={\n",
    "        \"default\": FeatureSpace.string_categorical(\n",
    "            num_oov_indices=1, output_mode=\"one_hot\"\n",
    "        )\n",
    "    },\n",
    "    output_mode=\"dict\",\n",
    ")\n",
    "example_feature_space(train_ds_with_no_labels, feature_space, [\"default\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [{'previously_contacted': 0}]\n",
      "Preprocessed output: [{'previously_contacted': array([1., 0.], dtype=float32)}]\n"
     ]
    }
   ],
   "source": [
    "feature_space = FeatureSpace(\n",
    "    features={\n",
    "        \"previously_contacted\": FeatureSpace.integer_categorical(\n",
    "            num_oov_indices=0, output_mode=\"one_hot\"\n",
    "        )\n",
    "    },\n",
    "    output_mode=\"dict\",\n",
    ")\n",
    "example_feature_space(train_ds_with_no_labels, feature_space, [\"previously_contacted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [{'age': 43}, {'job': b'blue-collar'}]\n",
      "Preprocessed output: [{'age': array([1., 0., 0., 0., 0., 0.], dtype=float32)}, {'job': array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)}, {'age_X_job': array([0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)}]\n"
     ]
    }
   ],
   "source": [
    "feature_space = FeatureSpace(\n",
    "    features={\n",
    "        \"age\": FeatureSpace.integer_hashed(num_bins=6, output_mode=\"one_hot\"),\n",
    "        \"job\": FeatureSpace.string_categorical(\n",
    "            num_oov_indices=0, output_mode=\"one_hot\"\n",
    "        ),\n",
    "    },\n",
    "    crosses=[\n",
    "        FeatureSpace.cross(\n",
    "            feature_names=(\"age\", \"job\"),\n",
    "            crossing_dim=8,\n",
    "            output_mode=\"one_hot\",\n",
    "        )\n",
    "    ],\n",
    "    output_mode=\"dict\",\n",
    ")\n",
    "example_feature_space(train_ds_with_no_labels, feature_space, [\"age\", \"job\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [{'education': b'basic.4y'}]\n",
      "Preprocessed output: [{'education': array([0.       , 0.       , 0.       , 0.       , 0.       , 2.3457654,\n",
      "       0.       , 0.       , 0.       ], dtype=float32)}]\n"
     ]
    }
   ],
   "source": [
    "custom_layer = keras.layers.TextVectorization(output_mode=\"tf_idf\")\n",
    "\n",
    "feature_space = FeatureSpace(\n",
    "    features={\n",
    "        \"education\": FeatureSpace.feature(\n",
    "            preprocessor=custom_layer, dtype=\"string\", output_mode=\"float\"\n",
    "        )\n",
    "    },\n",
    "    output_mode=\"dict\",\n",
    ")\n",
    "example_feature_space(train_ds_with_no_labels, feature_space, [\"education\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_space = FeatureSpace(\n",
    "    features={\n",
    "        # Categorical features encoded as integers\n",
    "        \"previously_contacted\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        # Categorical features encoded as string\n",
    "        \"marital\": FeatureSpace.string_categorical(num_oov_indices=0),\n",
    "        \"education\": FeatureSpace.string_categorical(num_oov_indices=0),\n",
    "        \"default\": FeatureSpace.string_categorical(num_oov_indices=0),\n",
    "        \"housing\": FeatureSpace.string_categorical(num_oov_indices=0),\n",
    "        \"loan\": FeatureSpace.string_categorical(num_oov_indices=0),\n",
    "        \"contact\": FeatureSpace.string_categorical(num_oov_indices=0),\n",
    "        \"month\": FeatureSpace.string_categorical(num_oov_indices=0),\n",
    "        \"day_of_week\": FeatureSpace.string_categorical(num_oov_indices=0),\n",
    "        \"poutcome\": FeatureSpace.string_categorical(num_oov_indices=0),\n",
    "        # Categorical features to hash and bin\n",
    "        \"job\": FeatureSpace.string_hashed(num_bins=3),\n",
    "        # Numerical features to hash and bin\n",
    "        \"pdays\": FeatureSpace.integer_hashed(num_bins=4),\n",
    "        # Numerical features to normalize and bin\n",
    "        \"age\": FeatureSpace.float_discretized(num_bins=4),\n",
    "        # Numerical features to normalize\n",
    "        \"campaign\": FeatureSpace.float_normalized(),\n",
    "        \"previous\": FeatureSpace.float_normalized(),\n",
    "        \"emp.var.rate\": FeatureSpace.float_normalized(),\n",
    "        \"cons.price.idx\": FeatureSpace.float_normalized(),\n",
    "        \"cons.conf.idx\": FeatureSpace.float_normalized(),\n",
    "        \"euribor3m\": FeatureSpace.float_normalized(),\n",
    "        \"nr.employed\": FeatureSpace.float_normalized(),\n",
    "    },\n",
    "    # Specify feature cross with a custom crossing dim.\n",
    "    crosses=[\n",
    "        FeatureSpace.cross(feature_names=(\"age\", \"job\"), crossing_dim=8),\n",
    "        FeatureSpace.cross(feature_names=(\"housing\", \"loan\"), crossing_dim=6),\n",
    "        FeatureSpace.cross(\n",
    "            feature_names=(\"poutcome\", \"previously_contacted\"), crossing_dim=2\n",
    "        ),\n",
    "    ],\n",
    "    output_mode=\"concat\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ppawa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:204: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_ds.batch(32)\n",
    "valid_ds = valid_ds.batch(32)\n",
    "\n",
    "train_ds_with_no_labels = train_ds.map(lambda x, _: x)\n",
    "feature_space.adapt(train_ds_with_no_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed_x shape: (32, 77)\n",
      "preprocessed_x sample: \n",
      "[ 0.          1.          0.          0.         -0.58789194  0.89378023\n",
      "  0.724956    0.          1.          0.          0.          0.\n",
      "  0.          1.          1.          0.          0.          0.\n",
      "  0.          0.          1.          0.          0.          0.\n",
      "  0.          0.6566937   0.7175757   1.          0.          0.\n",
      "  0.          0.          1.          1.          0.          0.\n",
      "  0.          0.          1.          0.          1.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.3375898   0.          0.          1.\n",
      "  0.          1.          0.          0.         -0.35691833  1.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  1.          0.          0.          0.          0.          0.\n",
      "  0.          1.          0.          1.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "for x, _ in train_ds.take(1):\n",
    "    preprocessed_x = feature_space(x)\n",
    "    print(f\"preprocessed_x shape: {preprocessed_x.shape}\")\n",
    "    print(f\"preprocessed_x sample: \\n{preprocessed_x[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_space.save(\"myfeaturespace.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train_ds = train_ds.map(\n",
    "    lambda x, y: (feature_space(x), y), num_parallel_calls=tf.data.AUTOTUNE\n",
    ").prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "preprocessed_valid_ds = valid_ds.map(\n",
    "    lambda x, y: (feature_space(x), y), num_parallel_calls=tf.data.AUTOTUNE\n",
    ").prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KerasTensor shape=(None, 77), dtype=float32, sparse=False, name=keras_tensor_56>\n"
     ]
    }
   ],
   "source": [
    "encoded_features = feature_space.get_encoded_features()\n",
    "print(encoded_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = keras.layers.Dense(64, activation=\"relu\")(encoded_features)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "output = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = keras.Model(inputs=encoded_features, outputs=output)\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "103/103 - 1s - 10ms/step - accuracy: 0.8680 - loss: 0.3693 - val_accuracy: 0.9102 - val_loss: 0.2656\n",
      "Epoch 2/20\n",
      "103/103 - 0s - 3ms/step - accuracy: 0.8944 - loss: 0.3009 - val_accuracy: 0.9078 - val_loss: 0.2640\n",
      "Epoch 3/20\n",
      "103/103 - 0s - 3ms/step - accuracy: 0.8986 - loss: 0.2906 - val_accuracy: 0.9102 - val_loss: 0.2626\n",
      "Epoch 4/20\n",
      "103/103 - 0s - 4ms/step - accuracy: 0.9005 - loss: 0.2872 - val_accuracy: 0.9102 - val_loss: 0.2617\n",
      "Epoch 5/20\n",
      "103/103 - 0s - 3ms/step - accuracy: 0.9032 - loss: 0.2826 - val_accuracy: 0.9078 - val_loss: 0.2628\n",
      "Epoch 6/20\n",
      "103/103 - 1s - 6ms/step - accuracy: 0.9011 - loss: 0.2841 - val_accuracy: 0.9090 - val_loss: 0.2637\n",
      "Epoch 7/20\n",
      "103/103 - 0s - 3ms/step - accuracy: 0.9017 - loss: 0.2821 - val_accuracy: 0.9102 - val_loss: 0.2609\n",
      "Epoch 8/20\n",
      "103/103 - 0s - 3ms/step - accuracy: 0.9020 - loss: 0.2802 - val_accuracy: 0.9078 - val_loss: 0.2632\n",
      "Epoch 9/20\n",
      "103/103 - 0s - 3ms/step - accuracy: 0.9017 - loss: 0.2801 - val_accuracy: 0.9041 - val_loss: 0.2648\n",
      "Epoch 10/20\n",
      "103/103 - 0s - 3ms/step - accuracy: 0.9032 - loss: 0.2802 - val_accuracy: 0.9078 - val_loss: 0.2615\n",
      "Epoch 11/20\n",
      "103/103 - 0s - 3ms/step - accuracy: 0.9002 - loss: 0.2789 - val_accuracy: 0.9066 - val_loss: 0.2625\n",
      "Epoch 12/20\n",
      "103/103 - 0s - 3ms/step - accuracy: 0.9008 - loss: 0.2764 - val_accuracy: 0.9066 - val_loss: 0.2632\n",
      "Epoch 13/20\n",
      "103/103 - 0s - 3ms/step - accuracy: 0.9005 - loss: 0.2770 - val_accuracy: 0.9090 - val_loss: 0.2609\n",
      "Epoch 14/20\n",
      "103/103 - 0s - 3ms/step - accuracy: 0.9041 - loss: 0.2713 - val_accuracy: 0.9090 - val_loss: 0.2613\n",
      "Epoch 15/20\n",
      "103/103 - 0s - 3ms/step - accuracy: 0.9032 - loss: 0.2736 - val_accuracy: 0.9078 - val_loss: 0.2645\n",
      "Epoch 16/20\n",
      "103/103 - 0s - 3ms/step - accuracy: 0.9029 - loss: 0.2693 - val_accuracy: 0.9066 - val_loss: 0.2637\n",
      "Epoch 17/20\n",
      "103/103 - 0s - 3ms/step - accuracy: 0.9074 - loss: 0.2654 - val_accuracy: 0.9053 - val_loss: 0.2650\n",
      "Epoch 18/20\n",
      "103/103 - 0s - 3ms/step - accuracy: 0.9071 - loss: 0.2680 - val_accuracy: 0.9066 - val_loss: 0.2626\n",
      "Epoch 19/20\n",
      "103/103 - 0s - 3ms/step - accuracy: 0.9062 - loss: 0.2663 - val_accuracy: 0.9078 - val_loss: 0.2624\n",
      "Epoch 20/20\n",
      "103/103 - 0s - 3ms/step - accuracy: 0.9044 - loss: 0.2640 - val_accuracy: 0.9066 - val_loss: 0.2626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x21cfa348590>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    preprocessed_train_ds, validation_data=preprocessed_valid_ds, epochs=20, verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_feature_space = keras.saving.load_model(\"myfeaturespace.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KerasTensor shape=(None, 77), dtype=float32, sparse=False, name=keras_tensor_99>\n",
      "{'previously_contacted': <KerasTensor shape=(None, 1), dtype=int32, sparse=False, name=previously_contacted>, 'marital': <KerasTensor shape=(None, 1), dtype=string, sparse=False, name=marital>, 'education': <KerasTensor shape=(None, 1), dtype=string, sparse=False, name=education>, 'default': <KerasTensor shape=(None, 1), dtype=string, sparse=False, name=default>, 'housing': <KerasTensor shape=(None, 1), dtype=string, sparse=False, name=housing>, 'loan': <KerasTensor shape=(None, 1), dtype=string, sparse=False, name=loan>, 'contact': <KerasTensor shape=(None, 1), dtype=string, sparse=False, name=contact>, 'month': <KerasTensor shape=(None, 1), dtype=string, sparse=False, name=month>, 'day_of_week': <KerasTensor shape=(None, 1), dtype=string, sparse=False, name=day_of_week>, 'poutcome': <KerasTensor shape=(None, 1), dtype=string, sparse=False, name=poutcome>, 'job': <KerasTensor shape=(None, 1), dtype=string, sparse=False, name=job>, 'pdays': <KerasTensor shape=(None, 1), dtype=int32, sparse=False, name=pdays>, 'age': <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=age>, 'campaign': <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=campaign>, 'previous': <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=previous>, 'emp.var.rate': <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=emp.var.rate>, 'cons.price.idx': <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=cons.price.idx>, 'cons.conf.idx': <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=cons.conf.idx>, 'euribor3m': <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=euribor3m>, 'nr.employed': <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=nr.employed>}\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step\n",
      "This particular client has a 6.43% probability of subscribing a term deposit, as evaluated by our model.\n"
     ]
    }
   ],
   "source": [
    "dict_inputs = loaded_feature_space.get_inputs()\n",
    "encoded_features = loaded_feature_space.get_encoded_features()\n",
    "print(encoded_features)\n",
    "\n",
    "print(dict_inputs)\n",
    "\n",
    "outputs = model(encoded_features)\n",
    "inference_model = keras.Model(inputs=dict_inputs, outputs=outputs)\n",
    "\n",
    "sample = {\n",
    "    \"age\": 30,\n",
    "    \"job\": \"blue-collar\",\n",
    "    \"marital\": \"married\",\n",
    "    \"education\": \"basic.9y\",\n",
    "    \"default\": \"no\",\n",
    "    \"housing\": \"yes\",\n",
    "    \"loan\": \"no\",\n",
    "    \"contact\": \"cellular\",\n",
    "    \"month\": \"may\",\n",
    "    \"day_of_week\": \"fri\",\n",
    "    \"campaign\": 2,\n",
    "    \"pdays\": 999,\n",
    "    \"previous\": 0,\n",
    "    \"poutcome\": \"nonexistent\",\n",
    "    \"emp.var.rate\": -1.8,\n",
    "    \"cons.price.idx\": 92.893,\n",
    "    \"cons.conf.idx\": -46.2,\n",
    "    \"euribor3m\": 1.313,\n",
    "    \"nr.employed\": 5099.1,\n",
    "    \"previously_contacted\": 0,\n",
    "}\n",
    "\n",
    "input_dict = {\n",
    "    name: keras.ops.convert_to_tensor([value]) for name, value in sample.items()\n",
    "}\n",
    "predictions = inference_model.predict(input_dict)\n",
    "\n",
    "print(\n",
    "    f\"This particular client has a {100 * predictions[0][0]:.2f}% probability \"\n",
    "    \"of subscribing a term deposit, as evaluated by our model.\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
