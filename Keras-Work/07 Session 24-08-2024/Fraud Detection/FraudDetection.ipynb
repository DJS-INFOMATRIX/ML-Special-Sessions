{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEADER: \"Time\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\",\"V16\",\"V17\",\"V18\",\"V19\",\"V20\",\"V21\",\"V22\",\"V23\",\"V24\",\"V25\",\"V26\",\"V27\",\"V28\",\"Amount\",\"Class\"\n",
      "EXAMPLE FEATURES: [0.0, -1.3598071336738, -0.0727811733098497, 2.53634673796914, 1.37815522427443, -0.338320769942518, 0.462387777762292, 0.239598554061257, 0.0986979012610507, 0.363786969611213, 0.0907941719789316, -0.551599533260813, -0.617800855762348, -0.991389847235408, -0.311169353699879, 1.46817697209427, -0.470400525259478, 0.207971241929242, 0.0257905801985591, 0.403992960255733, 0.251412098239705, -0.018306777944153, 0.277837575558899, -0.110473910188767, 0.0669280749146731, 0.128539358273528, -0.189114843888824, 0.133558376740387, -0.0210530534538215, 149.62]\n",
      "features.shape: (284807, 30)\n",
      "targets.shape: (284807, 1)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "fname = r\"C:\\Users\\ppawa\\Pranav\\Study\\Coding\\Generative Deep Learning\\Projects\\Datasets\\Fraud Detection\\creditcard.csv\"\n",
    "\n",
    "all_features = []\n",
    "all_targets = []\n",
    "with open(fname) as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i == 0:\n",
    "            print(\"HEADER:\", line.strip())\n",
    "            continue  # Skip header\n",
    "        fields = line.strip().split(\",\")\n",
    "        all_features.append([float(v.replace('\"', \"\")) for v in fields[:-1]])\n",
    "        all_targets.append([int(fields[-1].replace('\"', \"\"))])\n",
    "        if i == 1:\n",
    "            print(\"EXAMPLE FEATURES:\", all_features[-1])\n",
    "\n",
    "features = np.array(all_features, dtype=\"float32\")\n",
    "targets = np.array(all_targets, dtype=\"uint8\")\n",
    "print(\"features.shape:\", features.shape)\n",
    "print(\"targets.shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 227846\n",
      "Number of validation samples: 56961\n"
     ]
    }
   ],
   "source": [
    "num_val_samples = int(len(features) * 0.2)\n",
    "train_features = features[:-num_val_samples]\n",
    "train_targets = targets[:-num_val_samples]\n",
    "val_features = features[-num_val_samples:]\n",
    "val_targets = targets[-num_val_samples:]\n",
    "\n",
    "print(\"Number of training samples:\", len(train_features))\n",
    "print(\"Number of validation samples:\", len(val_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive samples in training data: 417 (0.18% of total)\n"
     ]
    }
   ],
   "source": [
    "counts = np.bincount(train_targets[:, 0])\n",
    "print(\n",
    "    \"Number of positive samples in training data: {} ({:.2f}% of total)\".format(\n",
    "        counts[1], 100 * float(counts[1]) / len(train_targets)\n",
    "    )\n",
    ")\n",
    "\n",
    "weight_for_0 = 1.0 / counts[0]\n",
    "weight_for_1 = 1.0 / counts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(train_features, axis=0)\n",
    "train_features -= mean\n",
    "val_features -= mean\n",
    "std = np.std(train_features, axis=0)\n",
    "train_features /= std\n",
    "val_features /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,936</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m7,936\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m65,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m65,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">139,777</span> (546.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m139,777\u001b[0m (546.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">139,777</span> (546.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m139,777\u001b[0m (546.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=train_features.shape[1:]),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "112/112 - 3s - 25ms/step - fn: 44.0000 - fp: 18032.0000 - loss: 2.2016e-06 - precision: 0.0203 - recall: 0.8945 - tn: 209397.0000 - tp: 373.0000 - val_fn: 9.0000 - val_fp: 1365.0000 - val_loss: 0.1348 - val_precision: 0.0461 - val_recall: 0.8800 - val_tn: 55521.0000 - val_tp: 66.0000\n",
      "Epoch 2/30\n",
      "112/112 - 1s - 10ms/step - fn: 34.0000 - fp: 6886.0000 - loss: 1.4070e-06 - precision: 0.0527 - recall: 0.9185 - tn: 220543.0000 - tp: 383.0000 - val_fn: 8.0000 - val_fp: 1144.0000 - val_loss: 0.0886 - val_precision: 0.0553 - val_recall: 0.8933 - val_tn: 55742.0000 - val_tp: 67.0000\n",
      "Epoch 3/30\n",
      "112/112 - 1s - 9ms/step - fn: 28.0000 - fp: 7126.0000 - loss: 1.2600e-06 - precision: 0.0518 - recall: 0.9329 - tn: 220303.0000 - tp: 389.0000 - val_fn: 9.0000 - val_fp: 1129.0000 - val_loss: 0.0788 - val_precision: 0.0552 - val_recall: 0.8800 - val_tn: 55757.0000 - val_tp: 66.0000\n",
      "Epoch 4/30\n",
      "112/112 - 1s - 9ms/step - fn: 29.0000 - fp: 8218.0000 - loss: 1.1785e-06 - precision: 0.0451 - recall: 0.9305 - tn: 219211.0000 - tp: 388.0000 - val_fn: 11.0000 - val_fp: 400.0000 - val_loss: 0.0298 - val_precision: 0.1379 - val_recall: 0.8533 - val_tn: 56486.0000 - val_tp: 64.0000\n",
      "Epoch 5/30\n",
      "112/112 - 1s - 10ms/step - fn: 20.0000 - fp: 6522.0000 - loss: 8.4260e-07 - precision: 0.0574 - recall: 0.9520 - tn: 220907.0000 - tp: 397.0000 - val_fn: 8.0000 - val_fp: 647.0000 - val_loss: 0.0375 - val_precision: 0.0938 - val_recall: 0.8933 - val_tn: 56239.0000 - val_tp: 67.0000\n",
      "Epoch 6/30\n",
      "112/112 - 1s - 10ms/step - fn: 22.0000 - fp: 6932.0000 - loss: 8.5823e-07 - precision: 0.0539 - recall: 0.9472 - tn: 220497.0000 - tp: 395.0000 - val_fn: 10.0000 - val_fp: 561.0000 - val_loss: 0.0319 - val_precision: 0.1038 - val_recall: 0.8667 - val_tn: 56325.0000 - val_tp: 65.0000\n",
      "Epoch 7/30\n",
      "112/112 - 1s - 9ms/step - fn: 16.0000 - fp: 6646.0000 - loss: 7.9950e-07 - precision: 0.0569 - recall: 0.9616 - tn: 220783.0000 - tp: 401.0000 - val_fn: 8.0000 - val_fp: 1533.0000 - val_loss: 0.0718 - val_precision: 0.0419 - val_recall: 0.8933 - val_tn: 55353.0000 - val_tp: 67.0000\n",
      "Epoch 8/30\n",
      "112/112 - 1s - 9ms/step - fn: 12.0000 - fp: 7315.0000 - loss: 7.6652e-07 - precision: 0.0525 - recall: 0.9712 - tn: 220114.0000 - tp: 405.0000 - val_fn: 7.0000 - val_fp: 1591.0000 - val_loss: 0.0529 - val_precision: 0.0410 - val_recall: 0.9067 - val_tn: 55295.0000 - val_tp: 68.0000\n",
      "Epoch 9/30\n",
      "112/112 - 1s - 10ms/step - fn: 11.0000 - fp: 7104.0000 - loss: 7.3208e-07 - precision: 0.0541 - recall: 0.9736 - tn: 220325.0000 - tp: 406.0000 - val_fn: 5.0000 - val_fp: 2131.0000 - val_loss: 0.1086 - val_precision: 0.0318 - val_recall: 0.9333 - val_tn: 54755.0000 - val_tp: 70.0000\n",
      "Epoch 10/30\n",
      "112/112 - 1s - 10ms/step - fn: 10.0000 - fp: 7224.0000 - loss: 6.1976e-07 - precision: 0.0533 - recall: 0.9760 - tn: 220205.0000 - tp: 407.0000 - val_fn: 10.0000 - val_fp: 380.0000 - val_loss: 0.0219 - val_precision: 0.1461 - val_recall: 0.8667 - val_tn: 56506.0000 - val_tp: 65.0000\n",
      "Epoch 11/30\n",
      "112/112 - 1s - 10ms/step - fn: 5.0000 - fp: 5259.0000 - loss: 4.4634e-07 - precision: 0.0727 - recall: 0.9880 - tn: 222170.0000 - tp: 412.0000 - val_fn: 8.0000 - val_fp: 510.0000 - val_loss: 0.0251 - val_precision: 0.1161 - val_recall: 0.8933 - val_tn: 56376.0000 - val_tp: 67.0000\n",
      "Epoch 12/30\n",
      "112/112 - 1s - 9ms/step - fn: 12.0000 - fp: 7450.0000 - loss: 6.5478e-07 - precision: 0.0516 - recall: 0.9712 - tn: 219979.0000 - tp: 405.0000 - val_fn: 9.0000 - val_fp: 811.0000 - val_loss: 0.0413 - val_precision: 0.0753 - val_recall: 0.8800 - val_tn: 56075.0000 - val_tp: 66.0000\n",
      "Epoch 13/30\n",
      "112/112 - 1s - 9ms/step - fn: 10.0000 - fp: 5980.0000 - loss: 5.6513e-07 - precision: 0.0637 - recall: 0.9760 - tn: 221449.0000 - tp: 407.0000 - val_fn: 7.0000 - val_fp: 1662.0000 - val_loss: 0.0620 - val_precision: 0.0393 - val_recall: 0.9067 - val_tn: 55224.0000 - val_tp: 68.0000\n",
      "Epoch 14/30\n",
      "112/112 - 1s - 9ms/step - fn: 6.0000 - fp: 6113.0000 - loss: 5.1023e-07 - precision: 0.0630 - recall: 0.9856 - tn: 221316.0000 - tp: 411.0000 - val_fn: 7.0000 - val_fp: 2771.0000 - val_loss: 0.0815 - val_precision: 0.0240 - val_recall: 0.9067 - val_tn: 54115.0000 - val_tp: 68.0000\n",
      "Epoch 15/30\n",
      "112/112 - 1s - 9ms/step - fn: 11.0000 - fp: 6538.0000 - loss: 7.2321e-07 - precision: 0.0585 - recall: 0.9736 - tn: 220891.0000 - tp: 406.0000 - val_fn: 7.0000 - val_fp: 601.0000 - val_loss: 0.0279 - val_precision: 0.1016 - val_recall: 0.9067 - val_tn: 56285.0000 - val_tp: 68.0000\n",
      "Epoch 16/30\n",
      "112/112 - 1s - 10ms/step - fn: 7.0000 - fp: 5310.0000 - loss: 4.9259e-07 - precision: 0.0717 - recall: 0.9832 - tn: 222119.0000 - tp: 410.0000 - val_fn: 9.0000 - val_fp: 786.0000 - val_loss: 0.0383 - val_precision: 0.0775 - val_recall: 0.8800 - val_tn: 56100.0000 - val_tp: 66.0000\n",
      "Epoch 17/30\n",
      "112/112 - 1s - 11ms/step - fn: 5.0000 - fp: 4335.0000 - loss: 3.9947e-07 - precision: 0.0868 - recall: 0.9880 - tn: 223094.0000 - tp: 412.0000 - val_fn: 11.0000 - val_fp: 217.0000 - val_loss: 0.0129 - val_precision: 0.2278 - val_recall: 0.8533 - val_tn: 56669.0000 - val_tp: 64.0000\n",
      "Epoch 18/30\n",
      "112/112 - 1s - 11ms/step - fn: 5.0000 - fp: 4993.0000 - loss: 4.3198e-07 - precision: 0.0762 - recall: 0.9880 - tn: 222436.0000 - tp: 412.0000 - val_fn: 7.0000 - val_fp: 680.0000 - val_loss: 0.0363 - val_precision: 0.0909 - val_recall: 0.9067 - val_tn: 56206.0000 - val_tp: 68.0000\n",
      "Epoch 19/30\n",
      "112/112 - 1s - 11ms/step - fn: 5.0000 - fp: 3848.0000 - loss: 3.2363e-07 - precision: 0.0967 - recall: 0.9880 - tn: 223581.0000 - tp: 412.0000 - val_fn: 9.0000 - val_fp: 830.0000 - val_loss: 0.0349 - val_precision: 0.0737 - val_recall: 0.8800 - val_tn: 56056.0000 - val_tp: 66.0000\n",
      "Epoch 20/30\n",
      "112/112 - 1s - 11ms/step - fn: 1.0000 - fp: 3484.0000 - loss: 2.9106e-07 - precision: 0.1067 - recall: 0.9976 - tn: 223945.0000 - tp: 416.0000 - val_fn: 10.0000 - val_fp: 523.0000 - val_loss: 0.0281 - val_precision: 0.1105 - val_recall: 0.8667 - val_tn: 56363.0000 - val_tp: 65.0000\n",
      "Epoch 21/30\n",
      "112/112 - 1s - 12ms/step - fn: 0.0000e+00 - fp: 2067.0000 - loss: 1.7482e-07 - precision: 0.1679 - recall: 1.0000 - tn: 225362.0000 - tp: 417.0000 - val_fn: 10.0000 - val_fp: 181.0000 - val_loss: 0.0104 - val_precision: 0.2642 - val_recall: 0.8667 - val_tn: 56705.0000 - val_tp: 65.0000\n",
      "Epoch 22/30\n",
      "112/112 - 1s - 10ms/step - fn: 1.0000 - fp: 2210.0000 - loss: 1.9402e-07 - precision: 0.1584 - recall: 0.9976 - tn: 225219.0000 - tp: 416.0000 - val_fn: 8.0000 - val_fp: 529.0000 - val_loss: 0.0294 - val_precision: 0.1124 - val_recall: 0.8933 - val_tn: 56357.0000 - val_tp: 67.0000\n",
      "Epoch 23/30\n",
      "112/112 - 1s - 10ms/step - fn: 0.0000e+00 - fp: 1669.0000 - loss: 1.4140e-07 - precision: 0.1999 - recall: 1.0000 - tn: 225760.0000 - tp: 417.0000 - val_fn: 8.0000 - val_fp: 446.0000 - val_loss: 0.0316 - val_precision: 0.1306 - val_recall: 0.8933 - val_tn: 56440.0000 - val_tp: 67.0000\n",
      "Epoch 24/30\n",
      "112/112 - 1s - 9ms/step - fn: 1.0000 - fp: 2448.0000 - loss: 2.0585e-07 - precision: 0.1453 - recall: 0.9976 - tn: 224981.0000 - tp: 416.0000 - val_fn: 9.0000 - val_fp: 319.0000 - val_loss: 0.0185 - val_precision: 0.1714 - val_recall: 0.8800 - val_tn: 56567.0000 - val_tp: 66.0000\n",
      "Epoch 25/30\n",
      "112/112 - 1s - 9ms/step - fn: 0.0000e+00 - fp: 1639.0000 - loss: 1.3474e-07 - precision: 0.2028 - recall: 1.0000 - tn: 225790.0000 - tp: 417.0000 - val_fn: 12.0000 - val_fp: 348.0000 - val_loss: 0.0182 - val_precision: 0.1533 - val_recall: 0.8400 - val_tn: 56538.0000 - val_tp: 63.0000\n",
      "Epoch 26/30\n",
      "112/112 - 1s - 11ms/step - fn: 1.0000 - fp: 1662.0000 - loss: 1.4147e-07 - precision: 0.2002 - recall: 0.9976 - tn: 225767.0000 - tp: 416.0000 - val_fn: 12.0000 - val_fp: 174.0000 - val_loss: 0.0103 - val_precision: 0.2658 - val_recall: 0.8400 - val_tn: 56712.0000 - val_tp: 63.0000\n",
      "Epoch 27/30\n",
      "112/112 - 1s - 10ms/step - fn: 1.0000 - fp: 3451.0000 - loss: 3.2075e-07 - precision: 0.1076 - recall: 0.9976 - tn: 223978.0000 - tp: 416.0000 - val_fn: 10.0000 - val_fp: 1037.0000 - val_loss: 0.0311 - val_precision: 0.0590 - val_recall: 0.8667 - val_tn: 55849.0000 - val_tp: 65.0000\n",
      "Epoch 28/30\n",
      "112/112 - 1s - 10ms/step - fn: 3.0000 - fp: 5101.0000 - loss: 4.2255e-07 - precision: 0.0751 - recall: 0.9928 - tn: 222328.0000 - tp: 414.0000 - val_fn: 6.0000 - val_fp: 3166.0000 - val_loss: 0.0837 - val_precision: 0.0213 - val_recall: 0.9200 - val_tn: 53720.0000 - val_tp: 69.0000\n",
      "Epoch 29/30\n",
      "112/112 - 1s - 10ms/step - fn: 4.0000 - fp: 5543.0000 - loss: 4.7732e-07 - precision: 0.0693 - recall: 0.9904 - tn: 221886.0000 - tp: 413.0000 - val_fn: 9.0000 - val_fp: 550.0000 - val_loss: 0.0240 - val_precision: 0.1071 - val_recall: 0.8800 - val_tn: 56336.0000 - val_tp: 66.0000\n",
      "Epoch 30/30\n",
      "112/112 - 1s - 10ms/step - fn: 6.0000 - fp: 6538.0000 - loss: 5.4161e-07 - precision: 0.0591 - recall: 0.9856 - tn: 220891.0000 - tp: 411.0000 - val_fn: 11.0000 - val_fp: 413.0000 - val_loss: 0.0187 - val_precision: 0.1342 - val_recall: 0.8533 - val_tn: 56473.0000 - val_tp: 64.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x256efaf3740>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = [\n",
    "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "    keras.metrics.FalsePositives(name=\"fp\"),\n",
    "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "    keras.metrics.TruePositives(name=\"tp\"),\n",
    "    keras.metrics.Precision(name=\"precision\"),\n",
    "    keras.metrics.Recall(name=\"recall\"),\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-2), loss=\"binary_crossentropy\", metrics=metrics\n",
    ")\n",
    "\n",
    "callbacks = [keras.callbacks.ModelCheckpoint(\"fraud_model_at_epoch_{epoch}.keras\")]\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "model.fit(\n",
    "    train_features,\n",
    "    train_targets,\n",
    "    batch_size=2048,\n",
    "    epochs=30,\n",
    "    verbose=2,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(val_features, val_targets),\n",
    "    class_weight=class_weight,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
